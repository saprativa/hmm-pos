{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzWcv1n6CKYD",
        "outputId": "3b725281-7372-4755-cd1e-dbff2657c228"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.8/298.8 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FRRspDGODv0",
        "outputId": "a0e15861-7770-4931-81e4-870d5463e956"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import pickle as pkl\n",
        "\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtTFahFrOVC-"
      },
      "outputs": [],
      "source": [
        "def load_object(filename):\n",
        "\n",
        "    file = open(filename, \"rb\")\n",
        "    obj = pkl.load(file)\n",
        "    file.close()\n",
        "    return obj\n",
        "\n",
        "initial = load_object(\"initial3.pkl\")\n",
        "emission = load_object(\"emission3.pkl\")\n",
        "transition = load_object(\"transition3.pkl\")\n",
        "\n",
        "word2id = load_object(\"word2id.pkl\")\n",
        "tag2id = load_object(\"tag2id.pkl\")\n",
        "id2tag = load_object(\"id2tag.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__lcMTpfOeZq"
      },
      "outputs": [],
      "source": [
        "def viterbi(text):\n",
        "\n",
        "    sent = nltk.word_tokenize(text)\n",
        "\n",
        "\n",
        "    viterbi = np.zeros((len(tag2id), len(sent)))\n",
        "    backpointer = np.zeros((len(tag2id), len(sent)))\n",
        "\n",
        "    for s in range(len(tag2id)):\n",
        "        if(sent[0] in word2id):\n",
        "            viterbi[s][0] = initial[s] + emission[s][word2id[sent[0]]]\n",
        "        else:\n",
        "            viterbi[s][0] = initial[s] + np.log(1/1000)\n",
        "        backpointer[s][0] = -1\n",
        "\n",
        "    for t in range(1, len(sent)):\n",
        "        for s in range(len(tag2id)):\n",
        "            temp = np.zeros((len(tag2id),))\n",
        "            for s_ in range(len(tag2id)):\n",
        "                if(sent[t] in word2id):\n",
        "                    temp[s_] = viterbi[s_][t-1] + transition[s_][s] + emission[s][word2id[sent[t]]]\n",
        "                else:\n",
        "                    temp[s_] = viterbi[s_][t-1] + transition[s_][s] + np.log(1/1000)\n",
        "\n",
        "            viterbi[s][t] = np.max(temp)\n",
        "            backpointer[s][t] = np.argmax(temp)\n",
        "\n",
        "    # bestpathprob = np.max(viterbi[:, -1])\n",
        "    bestpathpointer = np.argmax(viterbi[:, -1])\n",
        "\n",
        "    predicted_pos_sent = []\n",
        "\n",
        "    for i in reversed(range(len(sent))):\n",
        "        predicted_pos_sent.insert(0, bestpathpointer)\n",
        "        bestpathpointer = int(backpointer[bestpathpointer][i])\n",
        "\n",
        "    id_to_pos = [id2tag[i] for i in predicted_pos_sent]\n",
        "\n",
        "    tagged_sent = [i+\"_\"+j for (i,j) in zip(sent, id_to_pos)]\n",
        "\n",
        "    return(\" \".join(tagged_sent))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iODjZcLjOjlL",
        "outputId": "ca0b4e05-489d-4cbf-fd93-5d5a240a09a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'My_DET name_NOUN is_VERB Saprativa_NOUN ._.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "viterbi(\"My name is Saprativa.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "kyUCjUV1O3MJ",
        "outputId": "cde86a06-b4e6-492d-939a-dbf7cc612e83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://24cc8962d11dd5dde9.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://24cc8962d11dd5dde9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import gradio\n",
        "\n",
        "gradio.Interface(viterbi, \"text\", \"text\").launch(share=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}